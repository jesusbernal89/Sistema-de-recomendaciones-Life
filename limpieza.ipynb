{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sistema de recomendaciones de cusos Life \n",
        "\n",
        "Este notebook muestra solamente el proceso de preparación de los datos que se entrenarán en un modelo SVD en la plataforma de Azure Machine Learning Studio. Se encarga de leer los datasets necesarios y juntarlos de tal manera que tengamos un dataset final que sirva de entrada para el modelo. Este archivo se tiene que subir a la sección de notebooks de Azure Machine Learning Studio, donde se correrá cada vez que se tenga una actualización de datos. La salida se guardará en el datastore de forma automática, y el modelo podrá leerlo de manera directa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importar librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1653794087399
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import helper_functions\n",
        "from azureml.core import Workspace, Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuración del ambiente de Azure Machine Learning Studio \n",
        "\n",
        "En esta sección se tendrán que llenar las variables con los datos de la cuenta que esté corriendo el modelo. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1653794088088
        }
      },
      "outputs": [],
      "source": [
        "subscription_id = '-----'\n",
        "resource_group = '-----'\n",
        "workspace_name = '------'\n",
        "\n",
        "workspace = Workspace(subscription_id, resource_group, workspace_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lectura de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1653794088253
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def get_data(workspace, name):\n",
        "\n",
        "    dataset = Dataset.get_by_name(workspace, name=name)\n",
        "    return dataset.to_pandas_dataframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1653794102406
        }
      },
      "outputs": [],
      "source": [
        "enrollment_fact = get_data(workspace, 'enrollment_fact')# RELACIÓN ENTRE CURSOS, PERIODOS Y ESTUDIANTES\n",
        "course_dim = get_data(workspace, 'course_dim') # LISTA DE CURSOS EN GENERAL (ACADEMICOS Y EXTRA-ACADEMICOS)\n",
        "user_dim = get_data(workspace, 'user_dim') # LISTA DE ESTUDIANTES\n",
        "enrollment_term_dim = get_data(workspace, 'enrollment_term_dim')# LISTA DE PERIODOS \n",
        "pseudonym_dim = get_data(workspace, 'pseudonym_dim') # LISTA DE MATRICULAS\n",
        "ecoa = get_data(workspace, 'GRUPO_ECOA') # CALIFICACIONES DE ECOA\n",
        "alumno_df = get_data(workspace, 'DET_INT_ALUMNO') # RELACIÓN ESTUDIANTES CON ECOA Y MATERIAS\n",
        "cursos_life = get_data(workspace, 'DWH_MATERIAS_EXTRA_ACADEMICAS') # LISTA DE MATERIAS EXTRA ACADEMICAS\n",
        "materias_life = cursos_life.CLAVE_MATERIA.unique() # LISTA DE MATERIAS EXTRA ACADEMICAS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Selección de columnas necesarias y modificación al tipo de dato"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1653794114671
        }
      },
      "outputs": [],
      "source": [
        "enrollment_fact = helper_functions.int_to_str(enrollment_fact)\n",
        "course_dim = helper_functions.int_to_str(course_dim)\n",
        "user_dim = helper_functions.int_to_str(user_dim)\n",
        "enrollment_term_dim = helper_functions.int_to_str(enrollment_term_dim)\n",
        "pseudonym_dim = helper_functions.int_to_str(pseudonym_dim)\n",
        "alumno_df = helper_functions.int_to_str(alumno_df)\n",
        "cursos_life = helper_functions.int_to_str(cursos_life)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1653794114875
        }
      },
      "outputs": [],
      "source": [
        "# FILTRADO Y MODIFICACIÓN A COURSE_DIM\n",
        "\n",
        "course_dim.code = course_dim.code.apply(lambda x : x[:x.find('.')]) # Obtener códigos generales de las materias\n",
        "course_dim = course_dim[course_dim.code.isin(materias_life)] #HACER FILTRADO DE LAS MATERIAS QUE SOLO SON LIFE\n",
        "course_dim.rename(columns={'id':'course_id'}, inplace = True)\n",
        "course_dim = course_dim.loc[:, ['course_id','enrollment_term_id', 'name', 'code', 'start_at']] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1653794115227
        }
      },
      "outputs": [],
      "source": [
        "# FILTRADO Y MODIFICACIÓN A enrollment_fact\n",
        "\n",
        "enrollment_fact = enrollment_fact.loc[:, ['enrollment_id', 'user_id', 'course_id', 'enrollment_term_id']]\n",
        "enrollment_fact"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1653794115396
        }
      },
      "outputs": [],
      "source": [
        "# FILTRADO Y MODIFICACIÓN A user_dim\n",
        "\n",
        "user_dim.rename(columns={'id':'user_id', 'name':'user_name'}, inplace = True)\n",
        "user_dim = user_dim.loc[:, ['user_id', 'user_name', 'time_zone']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1653794115679
        }
      },
      "outputs": [],
      "source": [
        "# FILTRADO Y MODIFICACIÓN A user_dim\n",
        "\n",
        "pseudonym_dim.rename(columns={'unique_name':'matricula'}, inplace=True)\n",
        "pseudonym_dim = pseudonym_dim.loc[:, ['id', 'user_id', 'matricula']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creación de la tabla de alumnos y cursos únicos\n",
        "\n",
        "En este primer merge de los datasets podremos obtener un dataframe que contiene la lista de todos los alumnos y sus respectivas materias Life que han cursado. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1653794116566
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "tabla = pd.merge(enrollment_fact, course_dim, left_on=['course_id', 'enrollment_term_id' ], right_on=['course_id', 'enrollment_term_id'])\n",
        "tabla2 = pd.merge(tabla, user_dim, left_on=['user_id'], right_on=['user_id'])\n",
        "tabla3 = pd.merge(tabla2, pseudonym_dim, left_on=['user_id'], right_on=['user_id'])\n",
        "tabla3['start_at'] = tabla3['start_at'].apply(helper_functions.ddate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1653794116756
        }
      },
      "outputs": [],
      "source": [
        "ecoa.CLAVE_EJER_ACAD_GRUPO = ecoa.CLAVE_EJER_ACAD_GRUPO.astype('str')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creación de tabla con ratings\n",
        "\n",
        "En esta parte final obtendremos el rating que cada alumno calificó a su materia Life y se adjuntará a nuestra tabla de alumnos-materias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1653794149005
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:32<00:00,  3.10it/s]\n"
          ]
        }
      ],
      "source": [
        "final = pd.DataFrame(columns=['matricula', 'course_code', 'course_name', 'ratings'])\n",
        "\n",
        "for matricula in tqdm(tabla3.matricula.unique()[:100]):\n",
        "\n",
        "    df1 = tabla3[tabla3.matricula == matricula].loc[:, ['matricula', 'user_name', 'start_at', 'code']]\n",
        "    df2 = df1.merge(cursos_life, left_on=['code', 'start_at'], right_on=['CLAVE_MATERIA', 'CLAVE_EJERCICIO_ACADEMICO'])\n",
        "    df3 = df2.merge(alumno_df, left_on = ['CLAVE_CAMPUS', 'CLAVE_EJERCICIO_ACADEMICO', 'matricula'], \n",
        "                            right_on = ['CLAVE_CAMPUS', 'CLAVE_EJERCICIO_ACADEMICO', 'MATRICULA'])\n",
        "\n",
        "    df4 = df3.merge(ecoa, left_on = ['CLAVE_CAMPUS', 'CLAVE_EJERCICIO_ACADEMICO', 'CLAVE_MATERIA'],\n",
        "                            right_on = ['CLAVE_CAMPUS_GRUPO', 'CLAVE_EJER_ACAD_GRUPO', 'CLAVE_MATERIA'])\n",
        "\n",
        "    for c in df3.code.unique():\n",
        "        p = helper_functions.promedio_p(df4[(df4['code']==c)]['EVAL'])\n",
        "        df3.loc[(df3['code']==c), 'EVAL'] = int(p)\n",
        "\n",
        "    df3.rename(columns={'EVAL':'ratings'}, inplace= True)\n",
        "    final = pd.concat([final, df3])\n",
        "\n",
        "final = final.drop_duplicates(subset= ['matricula', 'code', 'course_name']).reset_index()\n",
        "final = final.loc[:, ['matricula', 'user_name', 'code', 'NOMBRE_MATERIA_CORTO', 'CLAVE_EJERCICIO_ACADEMICO', 'ratings']].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Registro del dataset final\n",
        "\n",
        "En esta última celda se hace el registro del dataset final en el datastore de Azureml studio. De esta forma, una vez registrado, el dataset podrá ser llamado por el modelo cuando se requiera entrenar. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1653794151166
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to managed-dataset/a44f93f7-30b4-4181-a4ad-b4fe879eed51/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n",
            "Successfully created and registered a new dataset.\n"
          ]
        }
      ],
      "source": [
        "datastore = workspace.get_default_datastore()\n",
        "# Uploading Pandas dataframe and registering it as a dataset\n",
        "dataset = Dataset.Tabular.register_pandas_dataframe(\n",
        "    final, datastore, \"final_dataframe\", show_progress=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "fb0fcf98fd656922d0fad1864d308e4ce1efa1d7fee702141d1c2245ebccf967"
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
